{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f4beef",
   "metadata": {},
   "source": [
    "# Sales Account Meeting Briefing\n",
    "\n",
    "**User Story**: US1 â€” Meeting Preparation Assistant\n",
    "**Persona**: Account Executive\n",
    "\n",
    "This notebook demonstrates how to use the Salesforce AI Assistant to prepare\n",
    "for account meetings. The assistant pulls live CRM data (account details, contacts,\n",
    "open opportunities, recent activities) and generates a comprehensive briefing\n",
    "with recommended talking points.\n",
    "\n",
    "## Prerequisites\n",
    "- `.env` file configured with Salesforce and Azure AI credentials\n",
    "- `salesforce-crm` MCP server available\n",
    "- Python packages installed (`pip install -r requirements.txt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Environment + Auth Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Verify required env vars\n",
    "required_vars = [\n",
    "    \"AZURE_AI_PROJECT_ENDPOINT\",\n",
    "    \"AZURE_OPENAI_DEPLOYMENT\",\n",
    "    \"SF_INSTANCE_URL\",\n",
    "    \"SF_ACCESS_TOKEN\",\n",
    "]\n",
    "missing = [v for v in required_vars if not os.environ.get(v)]\n",
    "if missing:\n",
    "    raise OSError(f\"Missing environment variables: {', '.join(missing)}\")\n",
    "\n",
    "print(\"âœ… Environment configured\")\n",
    "print(f\"   Project: {os.environ['AZURE_AI_PROJECT_ENDPOINT'][:50]}...\")\n",
    "print(f\"   SF Instance: {os.environ['SF_INSTANCE_URL']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Start MCP Server + Connect with MCP Client\n",
    "import asyncio\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import nest_asyncio\n",
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "\n",
    "nest_asyncio.apply()  # Allow nested event loops in Jupyter\n",
    "\n",
    "# Start the salesforce-crm MCP server locally with SSE transport\n",
    "MCP_PORT = 8100\n",
    "mcp_process = subprocess.Popen(\n",
    "    [sys.executable, \"-m\", \"mcp_servers.salesforce_crm.server\"],\n",
    "    env={**os.environ, \"MCP_TRANSPORT\": \"sse\", \"FASTMCP_PORT\": str(MCP_PORT)},\n",
    "    cwd=os.path.abspath(\"..\"),\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")\n",
    "time.sleep(3)\n",
    "\n",
    "if mcp_process.poll() is not None:\n",
    "    stderr = mcp_process.stderr.read().decode() if mcp_process.stderr else \"\"\n",
    "    raise RuntimeError(f\"MCP server failed to start: {stderr}\")\n",
    "\n",
    "MCP_URL = f\"http://127.0.0.1:{MCP_PORT}/sse\"\n",
    "print(f\"âœ… MCP server started (PID: {mcp_process.pid}) at {MCP_URL}\")\n",
    "\n",
    "\n",
    "# Connect to the MCP server via SSE and keep the session alive\n",
    "async def _connect():\n",
    "    \"\"\"Open an SSE connection and MCP session, return (sse_cm, session_cm, session, tools).\"\"\"\n",
    "    _sse_cm = sse_client(url=MCP_URL)\n",
    "    read_stream, write_stream = await _sse_cm.__aenter__()\n",
    "    _sess_cm = ClientSession(read_stream, write_stream)\n",
    "    session = await _sess_cm.__aenter__()\n",
    "    await session.initialize()\n",
    "    tools_result = await session.list_tools()\n",
    "    return _sse_cm, _sess_cm, session, tools_result.tools\n",
    "\n",
    "_sse_cm, _sess_cm, mcp_session, mcp_tools = asyncio.get_event_loop().run_until_complete(_connect())\n",
    "\n",
    "print(f\"âœ… MCP session connected â€” {len(mcp_tools)} tools available:\")\n",
    "for t in mcp_tools:\n",
    "    print(f\"   â€¢ {t.name}: {t.description[:80] if t.description else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa726973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create OpenAI Client + Load System Prompt + Define Helper\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Build an AzureOpenAI client using the base services endpoint.\n",
    "# The project endpoint looks like https://<host>/api/projects/<name>;\n",
    "# AzureOpenAI needs just https://<host>.\n",
    "_project_endpoint = os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"]\n",
    "_azure_endpoint = _project_endpoint.split(\"/api/\")[0] if \"/api/\" in _project_endpoint else _project_endpoint\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=_azure_endpoint,\n",
    "    azure_ad_token_provider=get_bearer_token_provider(\n",
    "        DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"\n",
    "    ),\n",
    "    api_version=\"2024-10-21\",\n",
    ")\n",
    "\n",
    "# Load the Sales agent system prompt\n",
    "system_prompt = _Path(\"../agents/sales/system_prompt.md\").read_text(encoding=\"utf-8\")\n",
    "MODEL = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o\")\n",
    "\n",
    "# ---------- Convert MCP tools â†’ OpenAI function-calling format ----------\n",
    "openai_tools = []\n",
    "for t in mcp_tools:\n",
    "    openai_tools.append(\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": t.name,\n",
    "                \"description\": t.description or \"\",\n",
    "                \"parameters\": t.inputSchema or {\"type\": \"object\", \"properties\": {}},\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "# ---------- Helper: run a query with automatic MCP tool-calling loop ----------\n",
    "async def _call_tool(name: str, arguments: dict) -> str:\n",
    "    \"\"\"Forward a tool call to the MCP server and return the text result.\"\"\"\n",
    "    result = await mcp_session.call_tool(name, arguments)\n",
    "    parts = []\n",
    "    for block in result.content:\n",
    "        if hasattr(block, \"text\"):\n",
    "            parts.append(block.text)\n",
    "    return \"\\n\".join(parts) if parts else \"\"\n",
    "\n",
    "\n",
    "def chat(user_message: str, *, history: list | None = None, max_rounds: int = 10) -> list:\n",
    "    \"\"\"Send *user_message* to the model, automatically executing any MCP tool\n",
    "    calls in a loop until the model produces a final text answer.\n",
    "\n",
    "    Returns the updated message history (for multi-turn continuation).\n",
    "    \"\"\"\n",
    "    if history is None:\n",
    "        history = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    history.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    for _ in range(max_rounds):\n",
    "        resp = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=history,\n",
    "            tools=openai_tools,\n",
    "            tool_choice=\"auto\",\n",
    "        )\n",
    "        msg = resp.choices[0].message\n",
    "\n",
    "        # Append the assistant message (may contain tool_calls)\n",
    "        history.append(msg)\n",
    "\n",
    "        if not msg.tool_calls:\n",
    "            break  # Final text answer\n",
    "\n",
    "        # Execute each tool call via MCP\n",
    "        for tc in msg.tool_calls:\n",
    "            args = json.loads(tc.function.arguments) if tc.function.arguments else {}\n",
    "            tool_result = loop.run_until_complete(_call_tool(tc.function.name, args))\n",
    "            history.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tc.id,\n",
    "                    \"content\": tool_result,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return history\n",
    "\n",
    "print(f\"âœ… OpenAI client ready (model: {MODEL})\")\n",
    "print(f\"âœ… System prompt loaded ({len(system_prompt)} chars)\")\n",
    "print(f\"âœ… {len(openai_tools)} MCP tools mapped to OpenAI functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930274f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Discover accounts in your Salesforce org\n",
    "import asyncio\n",
    "import json as _json\n",
    "\n",
    "_result = asyncio.get_event_loop().run_until_complete(\n",
    "    mcp_session.call_tool(\"search_accounts\", {\"query\": \"%\", \"limit\": 10})\n",
    ")\n",
    "_raw = \"\\n\".join(b.text for b in _result.content if hasattr(b, \"text\"))\n",
    "_data = _json.loads(_raw)\n",
    "\n",
    "print(\"Accounts in your Salesforce org:\")\n",
    "print(\"-\" * 50)\n",
    "for _acct in _data.get(\"accounts\", []):\n",
    "    print(f\"  â€¢ {_acct['name']}  (ID: {_acct['id']}, Industry: {_acct.get('industry', 'N/A')})\")\n",
    "print(f\"\\nTotal returned: {_data.get('total_count', 0)} | Has more: {_data.get('has_more', False)}\")\n",
    "print(\"\\nðŸ‘† Copy one of these names into ACCOUNT_NAME in the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Meeting Briefing Request\n",
    "ACCOUNT_NAME = \"GenePoint\"  # Change to your target account\n",
    "\n",
    "history = chat(\n",
    "    f\"Prepare me for my meeting with {ACCOUNT_NAME}. \"\n",
    "    f\"Include account overview, key contacts, open opportunities, \"\n",
    "    f\"recent activities, and suggested talking points.\"\n",
    ")\n",
    "print(\"âœ… Briefing generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e74fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Display Briefing\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def show(hist: list):\n",
    "    \"\"\"Display the last assistant message from history.\"\"\"\n",
    "    for m in reversed(hist):\n",
    "        content = m[\"content\"] if isinstance(m, dict) else m.content\n",
    "        role = m.get(\"role\") if isinstance(m, dict) else getattr(m, \"role\", None)\n",
    "        if role == \"assistant\" and content:\n",
    "            display(Markdown(content))\n",
    "            return\n",
    "\n",
    "\n",
    "show(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56fe7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Follow-up Question (continues conversation via history)\n",
    "history = chat(\n",
    "    \"Any other open opportunities with them? What's the total pipeline value?\",\n",
    "    history=history,\n",
    ")\n",
    "show(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Cleanup â€” close MCP session + stop server\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def _cleanup():\n",
    "    try:\n",
    "        await _sess_cm.__aexit__(None, None, None)\n",
    "    except (RuntimeError, Exception):\n",
    "        pass  # cancel-scope task mismatch is expected in Jupyter\n",
    "    try:\n",
    "        await _sse_cm.__aexit__(None, None, None)\n",
    "    except (RuntimeError, Exception):\n",
    "        pass\n",
    "\n",
    "try:\n",
    "    asyncio.get_event_loop().run_until_complete(_cleanup())\n",
    "except (RuntimeError, Exception):\n",
    "    pass\n",
    "\n",
    "mcp_process.terminate()\n",
    "mcp_process.wait(timeout=5)\n",
    "print(f\"âœ… MCP session closed & server stopped (PID: {mcp_process.pid})\")\n",
    "print(\"\\n--- Session Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
